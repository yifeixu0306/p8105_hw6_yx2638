---
title: "Homework 6"
author: "Yifei Xu"
date: "2022-12-02"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(purrr)
library(modelr)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

### Problem 1

First, import the dataset. 

```{r weather_df, cache = TRUE, message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

### Problem 2

First, import the dataset from the GitHub repository.

```{r, message=FALSE, warning=FALSE}
data_url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide = read_csv(url(data_url)) 
```

Second, clean the dataset as required.

```{r, message=FALSE, warning=FALSE}
homicide_tidy = homicide %>%
  janitor::clean_names() %>%
  mutate(state = toupper(state)) %>%
  mutate(city_state = str_c(city, state, sep = ", ")) %>%
  filter(!city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO")) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"),
         city_state = str_c(city, state, sep = ", "), 
         resolved = as.numeric(disposition == "Closed by arrest"),
         victim_age = as.numeric(victim_age),
         victim_sex = fct_relevel(victim_sex, "Female")) %>% 
  select(city_state, everything()) 

```

Third, fit a logistic regression for the city of Baltimore, MD.

```{r}
# filter out the records in Baltimore, MD
baltimore_df = homicide_tidy %>%
  filter(city_state == "Baltimore, MD") 

# GLE
fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) 

# summary
fit_summary = fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         conf_low = exp(estimate - 1.96 * std.error),
         conf_high = exp(estimate + 1.96 * std.error)) %>%
  select(term, OR, conf_low, conf_high) 

fit_summary

# sex
fit_summary %>%
  filter(term == "victim_sexMale")%>%
  mutate(term = str_replace(term, "victim_sex", "Sex: ")) %>%
  knitr::kable(col.names = c("Term", "Adjusted Odds Ratio", "Lower CI", "Upper CI"),
               caption = "Odds Ratio and CIs for Solving Homicides in Baltimore Comparing Male to Female",
               digits = 3)
  
```

The estimate of the adjusted odds ratio for solving homicides is 0.426 comparing male victims to female victims keeping all other variables fixed and its confidence interval is (0.325, 0.558). We can conclude that homicides in which the victim is male are significantly less like to be resolved than those in which the victim is female in Baltimore.

Fourth, run glm for each of the cities.

```{r}
city_gle = 
  homicide_tidy %>% 
  nest(data = -city_state) %>% 
  mutate(models = map(.x = data, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
         results = map(models, broom::tidy)) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(OR = exp(estimate),
         conf_low = exp(estimate - 1.96 * std.error),
         conf_high = exp(estimate + 1.96 * std.error)) %>% 
  select(city_state, term, OR, conf_low, conf_high) 

# sex
city_gle %>%
  filter(term == "victim_sexMale")%>%
  select(-term) %>%
  knitr::kable(col.names = c("City", "Adjusted Odds Ratio", "Lower CI", "Upper CI"),
               caption = "Odds Ratio and CIs for Solving Homicides Comparing Male to Female",
               digits = 3)

```

Finally, create a plot that shows the estimated ORs and CIs for each city.

```{r}
city_gle %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high)) + 
  labs(x = "City", 
       y = "Adjusted Odds Ratio",
       title = "Estimated Odds Ratio and CIs for Solving Homicides Comparing Male to Female") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 12))
```

For `r city_gle %>% filter(term == "victim_sexMale") %>% filter(OR<1) %>% summarise(count=n()/47) %>% pull() %>% scales::percent(0.01)` of the cities, the estimate odds ratio for solving homicides for males comparing to females is less than one. In addition, for some of those cities (OR<1) such as New York and Baton Rouge, the odds ratio confidence interval does not include 1, which means the homicides in which the victim is male are significantly less likely to be resolved than those in which the victim is female. For those cities whose confidence interval includes 1, we cannot immediately conclude that there is a significant difference in solving homicides between male and female.

### Problem 3 

### Data Import

```{r, message=FALSE}
birthweight = read_csv("data/birthweight.csv")
```

### Data Preprocessing

```{r}
birthweight_tidy =
  birthweight %>% 
  janitor::clean_names() %>%
  mutate(across(.cols = c(babysex, frace, malform, mrace), as.factor)) %>%
  mutate(babysex = case_when(babysex == 1 ~"male", babysex == 2 ~"female"),
         malform = case_when(malform == 0 ~"absent", malform == 1 ~ "present"),
         frace = recode(frace, 
                        "1" = "White", 
                        "2" = "Black", 
                        "3" = "Asian", 
                        "4" = "Puerto Rican", 
                        "8" = "Other", 
                        "9" = "Unknown"),
         mrace = recode(mrace, 
                        "1" = "White", 
                        "2" = "Black", 
                        "3" = "Asian", 
                        "4" = "Puerto Rican", 
                        "8" = "Other"))

# check missing values
sum(is.na(birthweight_tidy))

# Data summary
skimr::skim(birthweight_tidy)
```

### Propose a Regression Model for Birthweight

First, I use stepwise method to select variables.

```{r, message=FALSE}
mult_fit = lm(bwt ~ ., data=birthweight_tidy)
step(mult_fit, direction="both")
```

After stepwise selection, I get `babysex`, `bhead`, `blength`, `delwt`, `fincome`, `gaweeks`, `mheight`, `mrace`, `parity`, `ppwt` and `smoken` left in the model.

```{r}
mult_fit_1 = lm(bwt ~  babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken,
              data=birthweight_tidy)

summary(mult_fit_1)
```

Second, I would like to explore the collinearity among these selected continuous variables.

```{r, message=FALSE, warning=FALSE}
fit_var = birthweight_tidy %>%
  select(bhead, blength, delwt, fincome, gaweeks, mheight, parity, ppwt, smoken)

# Correlation matrix for all selected continuous variables
cor(fit_var)

# Scatter plot matrix for all selected continuous variables
pairs(fit_var)
```

From the plot above, we can observe that the a potential collinearity might exsit between `delwt` and `ppwt`, as well as `bhead` and `blength`. Therefore, I plan to drop `ppwt` and `blength` whose p-values are relatively larger.

```{r}
# remedy for collinearity
mult_fit_2 = lm(bwt ~  babysex + bhead + delwt + fincome + gaweeks + mheight + mrace + parity + smoken,
              data=birthweight_tidy)

summary(mult_fit_2)
```

From the summary, we find that `fincome` and `parity` have a p value of > 0.05, meaning that they are not significant. Therefore, I drop these two variables. My final model is bwt ~  babysex + bhead + delwt + gaweeks + mheight + mrace + smoken.

```{r}
# my final model
mult_fit_3 = lm(bwt ~  babysex + bhead + delwt + gaweeks + mheight + mrace + smoken,
              data=birthweight_tidy)

summary(mult_fit_3)
```

Next, I will show a plot of model residuals against fitted values.

```{r, message=FALSE}
birthweight_tidy %>%
  add_residuals(mult_fit_3) %>%
  add_predictions(mult_fit_3) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Plot of the Model Residuals Against Fitted Values",
       x = "Fitted Values", y = "Residuals") 
```

From the plot of residuals against fitted values above, we can observe a cluster around 0 when fitted values are between 2000 and 4000. However, when prediction is below 2000, residuals are not scattered around 0 and we can observe a curve. Therefore, the spread of residuals fail to be roughly equal at each level of fitted values and the constant variance assumption is slightly violated.

### Model Comparision

```{r,message=FALSE, warning=FALSE}
# use length at birth and gestational age as predictors
fit_com_1 = lm(bwt ~ blength + gaweeks, data = birthweight_tidy)
summary(fit_com_1)

# use head circumference, length, sex, and all interactions
fit_com_2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex,
               data = birthweight_tidy)
summary(fit_com_2)

# cross-validation 
set.seed(2022)

cv_df = 
  crossv_mc(birthweight_tidy, 100) %>% 
    mutate(
        train = map(train, as_tibble),
        test = map(test,as_tibble)
    )  %>%
  mutate(
    model_fit1  = map(train, ~lm(bwt ~ babysex + bhead + delwt + gaweeks + mheight + mrace + smoken,
                                 data = .x)),
    model_fit2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_fit3  = map(train, ~lm(bwt ~ blength + bhead + babysex + blength*bhead + blength* babysex + bhead*babysex + blength*bhead*babysex, data = .x))) %>% 
  mutate(
    rmse_1 = map2_dbl(model_fit1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model_fit2 , test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model_fit3, test, ~rmse(model = .x, data = .y))) 

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(title = "Comparison of the Cross-Validated Prediction Error", 
       x = "Models", 
       y = "Root Mean Square Error (RMSE)")  +
  scale_x_discrete(labels = c("My Model", "Test Model 1", "Test Model 2")) 
```

From RMSE distribution plot above, we can observe that the test model 2 (including interactions) has the lowest RMSE, representing a relatively better predictive ability, followed by my model and test model 1 (main effects only). Therefore, test model 2 is potentially the best model among these three models, which need to be further analyzed.














